# 08 - MySQL主从复制与集群 - 参考答案

## 一、主从复制配置（理论）

### 1. 主库配置

```ini
[mysqld]
# 服务器唯一ID，主从环境中必须唯一
server-id = 1

# 开启binlog
log-bin = mysql-bin

# binlog格式：ROW（推荐）、STATEMENT、MIXED
binlog-format = ROW

# binlog过期时间（秒），MySQL 8.0推荐使用
binlog_expire_logs_seconds = 604800  # 7天

# 或使用（MySQL 5.7）
# expire_logs_days = 7

# 需要复制的数据库（可选，不指定则复制所有）
# binlog-do-db = study_db

# 忽略复制的数据库（可选）
# binlog-ignore-db = mysql
# binlog-ignore-db = information_schema
```

**配置说明**：
- `server-id`：集群中每个MySQL实例必须唯一，通常使用IP最后一位或自增序号
- `log-bin`：二进制日志文件名前缀
- `binlog-format`：
  - ROW：记录每行数据的变化（推荐，数据一致性最好）
  - STATEMENT：记录SQL语句（日志小，但可能不一致）
  - MIXED：混合模式，自动选择

### 2. 从库配置

**从库my.cnf配置**：
```ini
[mysqld]
# 从库唯一ID（不能与主库相同）
server-id = 2

# 开启binlog（用于级联复制）
log-bin = mysql-bin

# 开启relay log
relay-log = relay-bin

# 从库只读（防止误写入）
read_only = 1
super_read_only = 1

# relay log自动清理
relay_log_purge = 1
```

**从库SQL配置**：
```sql
-- 1. 在主库创建复制用户
-- 在主库执行
CREATE USER 'repl_user'@'%' IDENTIFIED BY 'repl_password';
GRANT REPLICATION SLAVE ON *.* TO 'repl_user'@'%';
FLUSH PRIVILEGES;

-- 2. 获取主库binlog位置
SHOW MASTER STATUS;
-- 记录File和Position，例如：mysql-bin.000001, 154

-- 3. 在从库配置主库连接
CHANGE MASTER TO
  MASTER_HOST = '主库IP或主机名',
  MASTER_PORT = 3306,
  MASTER_USER = 'repl_user',
  MASTER_PASSWORD = 'repl_password',
  MASTER_LOG_FILE = 'mysql-bin.000001',
  MASTER_LOG_POS = 154;

-- 4. 启动从库复制
START SLAVE;

-- 5. 查看从库状态
SHOW SLAVE STATUS\G
```

## 二、主从状态监控

### 3. 查看主库状态

```sql
SHOW MASTER STATUS;
```

**结果示例**：
```
+------------------+----------+--------------+------------------+-------------------+
| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |
+------------------+----------+--------------+------------------+-------------------+
| mysql-bin.000003 |     1234 |              |                  |                   |
+------------------+----------+--------------+------------------+-------------------+
```

**字段含义**：
- **File**: 当前正在写入的binlog文件名
- **Position**: 当前binlog文件的写入位置（字节偏移量）
- **Binlog_Do_DB**: 配置的需要记录binlog的数据库
- **Binlog_Ignore_DB**: 配置的忽略binlog的数据库
- **Executed_Gtid_Set**: 已执行的GTID集合（GTID模式下）

**查看所有binlog文件**：
```sql
SHOW BINARY LOGS;
```

### 4. 查看从库状态

```sql
SHOW SLAVE STATUS\G
```

**重要字段解释**：

1. **Slave_IO_Running: Yes/No**
   - 表示IO线程是否正常运行
   - IO线程负责从主库读取binlog并写入relay log
   - 如果为No，检查网络、主库连接、用户权限

2. **Slave_SQL_Running: Yes/No**
   - 表示SQL线程是否正常运行
   - SQL线程负责执行relay log中的SQL
   - 如果为No，通常是数据冲突或SQL错误

3. **Seconds_Behind_Master: 数字/NULL**
   - 从库落后主库的秒数
   - NULL表示IO线程未运行
   - 0表示完全同步
   - >0表示存在延迟

4. **Last_IO_Error: 错误信息**
   - IO线程最后的错误信息
   - 常见错误：连接失败、权限不足、网络问题

5. **Last_SQL_Error: 错误信息**
   - SQL线程最后的错误信息
   - 常见错误：主键冲突、数据类型不匹配、表不存在

**其他重要字段**：
- `Master_Host`: 主库地址
- `Master_Log_File`: 从库正在读取的主库binlog文件
- `Read_Master_Log_Pos`: 从库读取的主库binlog位置
- `Relay_Log_File`: 当前relay log文件
- `Relay_Log_Pos`: 当前relay log位置
- `Exec_Master_Log_Pos`: 从库已执行到主库binlog的位置

### 5. 检测同步延迟

**方法1：通过SHOW SLAVE STATUS**
```sql
-- 查看延迟
SHOW SLAVE STATUS\G
-- 关注Seconds_Behind_Master字段

-- 或用SQL提取
SELECT
    IF(Slave_IO_Running = 'Yes', '正常', '异常') AS IO线程状态,
    IF(Slave_SQL_Running = 'Yes', '正常', '异常') AS SQL线程状态,
    Seconds_Behind_Master AS 延迟秒数
FROM (
    SELECT
        SUBSTRING_INDEX(SUBSTRING_INDEX(status, 'Slave_IO_Running: ', -1), '\n', 1) AS Slave_IO_Running,
        SUBSTRING_INDEX(SUBSTRING_INDEX(status, 'Slave_SQL_Running: ', -1), '\n', 1) AS Slave_SQL_Running,
        CAST(SUBSTRING_INDEX(SUBSTRING_INDEX(status, 'Seconds_Behind_Master: ', -1), '\n', 1) AS UNSIGNED) AS Seconds_Behind_Master
    FROM (
        SELECT CONCAT_WS('\n',
            CONCAT('Slave_IO_Running: ', @@global.slave_io_running),
            CONCAT('Slave_SQL_Running: ', @@global.slave_sql_running)
        ) AS status
    ) t
) result;

-- 实际使用时更简单的方式（MySQL 8.0+）
SELECT
    CHANNEL_NAME AS 复制通道,
    SERVICE_STATE AS 服务状态,
    LAST_ERROR_MESSAGE AS 最后错误
FROM performance_schema.replication_connection_status;
```

**方法2：心跳表检测**
```sql
-- 在主库创建心跳表
CREATE TABLE heartbeat (
    id INT PRIMARY KEY AUTO_INCREMENT,
    ts TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    server_id INT
) ENGINE=InnoDB;

-- 插入初始数据
INSERT INTO heartbeat (server_id) VALUES (1);

-- 主库定期更新（可以用事件调度器）
CREATE EVENT update_heartbeat
ON SCHEDULE EVERY 1 SECOND
DO
  UPDATE heartbeat SET ts = NOW() WHERE id = 1;

-- 启用事件调度器
SET GLOBAL event_scheduler = ON;

-- 在从库查询延迟
SELECT
    id,
    ts AS 主库心跳时间,
    NOW() AS 当前时间,
    TIMESTAMPDIFF(SECOND, ts, NOW()) AS 延迟秒数
FROM heartbeat WHERE id = 1;
```

**方法3：使用Performance Schema（MySQL 5.7+）**
```sql
-- 查看复制延迟详情
SELECT
    CHANNEL_NAME,
    LAST_APPLIED_TRANSACTION,
    LAST_APPLIED_TRANSACTION_ORIGINAL_COMMIT_TIMESTAMP,
    LAST_APPLIED_TRANSACTION_END_APPLY_TIMESTAMP,
    TIMESTAMPDIFF(MICROSECOND,
        LAST_APPLIED_TRANSACTION_ORIGINAL_COMMIT_TIMESTAMP,
        LAST_APPLIED_TRANSACTION_END_APPLY_TIMESTAMP
    ) / 1000000 AS lag_seconds
FROM performance_schema.replication_applier_status_by_worker;
```

## 三、主从同步问题处理

### 6. 处理同步中断

**场景分析**：

**情况1：测试环境 - 跳过错误**（不推荐生产环境）
```sql
-- 查看错误
SHOW SLAVE STATUS\G
-- 查看Last_SQL_Error字段

-- 停止从库
STOP SLAVE;

-- 跳过1个错误
SET GLOBAL sql_slave_skip_counter = 1;

-- 重新启动从库
START SLAVE;

-- 验证状态
SHOW SLAVE STATUS\G
```

**何时可以跳过错误**：
- 测试环境
- 已确认错误不影响数据一致性
- 从库仅用于查询，允许少量数据不一致

**情况2：GTID模式 - 跳过特定GTID**
```sql
-- 查看错误的GTID
SHOW SLAVE STATUS\G
-- 查看Retrieved_Gtid_Set和Executed_Gtid_Set

-- 假设错误的GTID是：3E11FA47-71CA-11E1-9E33-C80AA9429562:23
STOP SLAVE;

SET GTID_NEXT = '3E11FA47-71CA-11E1-9E33-C80AA9429562:23';
BEGIN;
COMMIT;
SET GTID_NEXT = 'AUTOMATIC';

START SLAVE;
```

**生产环境最佳实践**：
1. **不要随意跳过错误** - 可能导致数据不一致
2. **分析错误原因** - 查看Last_SQL_Error详细信息
3. **手动修复数据** - 修正冲突后再继续同步
4. **重新搭建从库** - 如果数据已严重不一致

```sql
-- 生产环境推荐流程
-- 1. 停止从库
STOP SLAVE;

-- 2. 分析错误
SHOW SLAVE STATUS\G

-- 3. 在从库手动执行修复
-- 例如：删除冲突数据、修改数据等

-- 4. 继续同步
START SLAVE;

-- 5. 验证
SHOW SLAVE STATUS\G
```

### 7. 处理主键冲突

**错误信息**：
```
Last_SQL_Error: Error 'Duplicate entry '1234' for key 'PRIMARY'' on query...
```

**方案1：删除从库冲突数据**
```sql
-- 1. 查看冲突数据
SELECT * FROM 表名 WHERE id = 1234;

-- 2. 确认主库数据
-- 在主库执行
SELECT * FROM 表名 WHERE id = 1234;

-- 3. 在从库删除冲突数据
STOP SLAVE;
DELETE FROM 表名 WHERE id = 1234;
START SLAVE;

-- 4. 验证同步恢复
SHOW SLAVE STATUS\G
```

**方案2：从库设置为忽略重复键错误**（临时方案）
```sql
-- 仅用于临时解决，不推荐长期使用
STOP SLAVE;
SET GLOBAL slave_exec_mode = 'IDEMPOTENT';  -- 幂等模式，忽略重复键和键不存在错误
START SLAVE;

-- 问题解决后改回严格模式
STOP SLAVE;
SET GLOBAL slave_exec_mode = 'STRICT';
START SLAVE;
```

**方案3：重新搭建从库**（最彻底）
```sql
-- 在主库
FLUSH TABLES WITH READ LOCK;
SHOW MASTER STATUS;  -- 记录File和Position

-- 备份数据
mysqldump -uroot -p --single-transaction --master-data=2 study_db > backup.sql

-- 解锁
UNLOCK TABLES;

-- 在从库
-- 导入数据
mysql -uroot -p study_db < backup.sql

-- 重新配置主从
STOP SLAVE;
RESET SLAVE;
CHANGE MASTER TO
  MASTER_HOST = '主库IP',
  MASTER_USER = 'repl_user',
  MASTER_PASSWORD = 'repl_password',
  MASTER_LOG_FILE = '记录的File',
  MASTER_LOG_POS = 记录的Position;
START SLAVE;
```

**根本原因分析**：
- 从库被误写入数据
- 主从配置不当（从库未设置read_only）
- 应用连接到从库执行了写操作

**预防措施**：
```sql
-- 从库设置只读
SET GLOBAL read_only = 1;
SET GLOBAL super_read_only = 1;  -- 包括超级用户

-- 应用使用普通用户连接从库（受read_only限制）
```

## 四、GTID复制

### 8. 启用GTID

**主库和从库配置**（my.cnf）：
```ini
[mysqld]
# 启用GTID
gtid-mode = ON
enforce-gtid-consistency = ON

# 自动定位binlog位置
log-slave-updates = ON

# 其他必要配置
server-id = 1  # 从库改为2
log-bin = mysql-bin
binlog-format = ROW
```

**从库配置主从复制**：
```sql
-- 停止旧的复制
STOP SLAVE;

-- 重置从库信息（可选，新从库跳过此步）
RESET SLAVE ALL;

-- 配置主库信息（GTID模式）
CHANGE MASTER TO
  MASTER_HOST = '192.168.1.100',
  MASTER_PORT = 3306,
  MASTER_USER = 'repl_user',
  MASTER_PASSWORD = 'repl_password',
  MASTER_AUTO_POSITION = 1;  -- 关键：使用GTID自动定位

-- 启动从库
START SLAVE;

-- 查看状态
SHOW SLAVE STATUS\G
-- 关注：
-- Auto_Position: 1
-- Retrieved_Gtid_Set: 已接收的GTID
-- Executed_Gtid_Set: 已执行的GTID
```

**GTID的优势**：
1. 故障切换更简单（不需要找binlog位置）
2. 一致性更好（全局唯一事务ID）
3. 方便搭建新从库

### 9. GTID状态查询

```sql
-- 查看已执行的GTID集合
SHOW GLOBAL VARIABLES LIKE 'gtid_executed';
-- 结果示例：3E11FA47-71CA-11E1-9E33-C80AA9429562:1-5

-- 查看已清理的GTID集合
SHOW GLOBAL VARIABLES LIKE 'gtid_purged';

-- 查看GTID拥有的UUID
SHOW GLOBAL VARIABLES LIKE 'gtid_owned';

-- 查看当前事务的GTID
SELECT @@session.gtid_next;

-- 使用Performance Schema查看复制状态
SELECT * FROM performance_schema.replication_connection_status\G

-- 查看GTID详细信息
SELECT
    CHANNEL_NAME AS 通道名,
    SOURCE_UUID AS 源UUID,
    RECEIVED_TRANSACTION_SET AS 已接收GTID,
    LAST_ERROR_NUMBER AS 错误编号,
    LAST_ERROR_MESSAGE AS 错误消息
FROM performance_schema.replication_connection_status;

-- 查看已应用的GTID
SELECT
    CHANNEL_NAME AS 通道名,
    SERVICE_STATE AS 服务状态,
    LAST_APPLIED_TRANSACTION AS 最后应用事务
FROM performance_schema.replication_applier_status;
```

**GTID格式说明**：
```
source_id:transaction_id
例如：3E11FA47-71CA-11E1-9E33-C80AA9429562:1-10

source_id: 服务器UUID（show variables like 'server_uuid'）
transaction_id: 事务序号（可以是范围，如1-10表示1到10号事务）
```

**检查GTID gaps（丢失的事务）**：
```sql
-- 比较主库和从库的GTID
-- 主库
SELECT @@global.gtid_executed AS master_gtid;

-- 从库
SELECT @@global.gtid_executed AS slave_gtid;

-- 如果从库缺少某些GTID，说明有事务丢失
```

## 五、读写分离场景

### 10. 设计读写分离架构

**架构设计**：
```
应用层
  ↓
代理层（ProxySQL/MaxScale/应用程序路由）
  ├─→ 主库（写）
  └─→ 从库1、从库2（读）- 负载均衡
```

**SQL路由策略**：

**场景1：查询自己刚创建的订单（强一致性）**
```sql
-- 用户刚下单后立即查询订单详情
SELECT * FROM orders WHERE user_id = 123 AND order_id = 10001;

-- 路由策略：主库
-- 原因：刚写入的数据，从库可能存在延迟，必须从主库读取保证一致性
```

**场景2：查询历史订单列表（弱一致性）**
```sql
-- 查询订单列表，允许一定延迟
SELECT * FROM orders
WHERE user_id = 123
ORDER BY created_at DESC
LIMIT 20;

-- 路由策略：从库（轮询或加权负载均衡）
-- 原因：历史数据，允许秒级延迟，从库读取减轻主库压力
```

**写后读一致性解决方案**：

**方案1：强制主库读取（Session级别）**
```sql
-- 伪代码
BEGIN TRANSACTION;
  -- 写操作
  INSERT INTO orders (...) VALUES (...);
  -- 同一事务内的读操作，强制走主库
  SELECT * FROM orders WHERE id = LAST_INSERT_ID();
COMMIT;

-- 或使用Hint
SELECT /*+ READ_FROM_MASTER */ * FROM orders WHERE id = 10001;
```

**方案2：延迟读取**
```python
# 应用层实现
# 写入后等待一段时间再读取（如100ms）
order_id = create_order(user_id, items)
time.sleep(0.1)  # 等待主从同步
order = get_order(order_id)  # 此时可以从从库读取
```

**方案3：会话级路由**
```python
# 写操作后的N秒内，该用户的所有读操作都走主库
class DatabaseRouter:
    def route(self, user_id, operation):
        if operation == 'write':
            cache.set(f'user_{user_id}_wrote', True, timeout=5)  # 5秒
            return 'MASTER'
        elif operation == 'read':
            if cache.get(f'user_{user_id}_wrote'):
                return 'MASTER'  # 近期有写操作，走主库
            else:
                return 'SLAVE'   # 否则走从库
```

**方案4：基于GTID的一致性读取**
```sql
-- 主库写入后获取GTID
-- 主库
INSERT INTO orders (...) VALUES (...);
SELECT @@session.gtid_executed;  -- 获取刚才事务的GTID

-- 从库等待该GTID执行完成后再读取
-- 从库
SELECT WAIT_FOR_EXECUTED_GTID_SET('3E11FA47:100', 1);  -- 等待最多1秒
SELECT * FROM orders WHERE id = 10001;
```

**从库故障降级方案**：

**方案1：摘除故障从库**
```python
class SlaveHealthCheck:
    def check_slave(self, slave):
        # 检查从库健康状态
        result = slave.query("SHOW SLAVE STATUS")
        if result['Slave_IO_Running'] != 'Yes' or \
           result['Slave_SQL_Running'] != 'Yes' or \
           result['Seconds_Behind_Master'] > 10:
            # 从库不健康，从读池中移除
            read_pool.remove(slave)
            alert("从库故障", slave.host)
```

**方案2：降级到主库**
```python
def get_read_connection():
    if len(slave_pool) == 0:
        logger.warning("所有从库不可用，降级到主库读取")
        return master_connection
    else:
        return random.choice(slave_pool)
```

**方案3：限流保护主库**
```python
from ratelimit import limits

@limits(calls=1000, period=1)  # 每秒最多1000次查询
def read_from_master():
    return master.query(sql)
```

## 六、延迟复制（Delayed Replication）

### 11. 配置延迟从库

```sql
-- 配置延迟30分钟（1800秒）的从库
STOP SLAVE;

CHANGE MASTER TO MASTER_DELAY = 1800;

START SLAVE;

-- 查看延迟配置
SHOW SLAVE STATUS\G
```

**关键字段**：
- `SQL_Delay`: 配置的延迟时间（秒）
- `SQL_Remaining_Delay`: 剩余延迟时间
- `Slave_SQL_Running_State`: 显示"Waiting until MASTER_DELAY seconds after master executed event"

**应用场景**：

**场景1：防止误删除数据**
```
时间线：
10:00 - 主库误删除数据
10:01 - 发现误删除
10:05 - 从延迟从库（延迟30分钟）恢复数据

因为延迟从库在10:30才会执行删除操作，有30分钟窗口期恢复数据
```

**场景2：数据恢复流程**
```sql
-- 1. 假设10:00误删除了数据
DELETE FROM orders WHERE id BETWEEN 1000 AND 1100;

-- 2. 在10:10发现问题，延迟从库还未执行删除

-- 3. 停止延迟从库复制
-- 在延迟从库执行
STOP SLAVE;

-- 4. 从延迟从库导出数据
mysqldump -uroot -p --single-transaction \
  study_db orders --where="id BETWEEN 1000 AND 1100" > recover.sql

-- 5. 恢复到主库
mysql -uroot -p study_db < recover.sql

-- 6. 重新启动延迟从库（会同步删除操作，但数据已恢复到主库）
START SLAVE;
```

**场景3：延迟从库作为备份窗口**
- 每日凌晨备份时，从延迟从库备份
- 不影响主库和实时从库性能
- 即使备份期间主库有误操作，延迟从库还未同步

## 七、半同步复制

### 12. 启用半同步复制

**主库配置**：
```sql
-- 安装半同步主库插件
INSTALL PLUGIN rpl_semi_sync_master SONAME 'semisync_master.so';

-- 启用半同步
SET GLOBAL rpl_semi_sync_master_enabled = 1;

-- 设置超时时间（毫秒）
SET GLOBAL rpl_semi_sync_master_timeout = 1000;  -- 1秒

-- 等待从库数量（MySQL 5.7.3+）
SET GLOBAL rpl_semi_sync_master_wait_for_slave_count = 1;

-- 写入my.cnf持久化
-- [mysqld]
-- rpl_semi_sync_master_enabled = 1
-- rpl_semi_sync_master_timeout = 1000
```

**从库配置**：
```sql
-- 安装半同步从库插件
INSTALL PLUGIN rpl_semi_sync_slave SONAME 'semisync_slave.so';

-- 启用半同步
SET GLOBAL rpl_semi_sync_slave_enabled = 1;

-- 重启IO线程使配置生效
STOP SLAVE IO_THREAD;
START SLAVE IO_THREAD;

-- 持久化配置
-- [mysqld]
-- rpl_semi_sync_slave_enabled = 1
```

**查看半同步状态**：
```sql
SHOW STATUS LIKE 'Rpl_semi_sync%';
```

**状态变量含义**：

| 变量名 | 含义 |
|--------|------|
| `Rpl_semi_sync_master_clients` | 当前连接的半同步从库数量 |
| `Rpl_semi_sync_master_status` | 半同步是否激活（ON/OFF） |
| `Rpl_semi_sync_master_yes_tx` | 成功以半同步方式提交的事务数 |
| `Rpl_semi_sync_master_no_tx` | 降级为异步提交的事务数 |
| `Rpl_semi_sync_master_wait_sessions` | 当前等待从库确认的会话数 |
| `Rpl_semi_sync_master_wait_pos_backtraverse` | 等待位置回退次数 |
| `Rpl_semi_sync_master_timefunc_failures` | 时间函数调用失败次数 |
| `Rpl_semi_sync_master_tx_avg_wait_time` | 事务平均等待时间（微秒） |
| `Rpl_semi_sync_master_tx_wait_time` | 事务总等待时间（微秒） |
| `Rpl_semi_sync_master_net_avg_wait_time` | 网络平均等待时间（微秒） |

**示例输出**：
```
Rpl_semi_sync_master_clients: 2
Rpl_semi_sync_master_status: ON
Rpl_semi_sync_master_yes_tx: 12458
Rpl_semi_sync_master_no_tx: 3
```

**解读**：
- 有2个从库连接并启用半同步
- 半同步当前激活
- 12458个事务成功以半同步提交
- 3个事务因超时降级为异步（可能是网络延迟或从库慢）

**半同步降级场景**：
- 从库宕机
- 网络延迟超过timeout
- 从库处理慢导致超时

半同步降级为异步后不会阻塞事务，但数据一致性保障降低。

## 八、高可用架构

### 13. MHA故障切换流程

**MHA（Master High Availability）故障切换流程**：

**1. 监测主库故障**
```bash
# MHA Manager定期检测主库
# 通过以下方式判断主库是否故障：
- TCP连接检测
- SELECT 1探测
- 多次重试（避免网络抖动误判）
```

**2. 选择新主库的条件**
```
优先级排序：
1. 数据最完整的从库（Executed_Gtid_Set最多或binlog位置最新）
2. 复制延迟最小的从库（Seconds_Behind_Master最小）
3. 配置的优先级（candidate_master=1）
4. 排除标记为no_master的从库

选择算法：
- 比较各从库的relay log位置
- 选择最接近主库的从库
```

**3. 数据补偿（差异日志）**
```sql
-- MHA会做以下操作：
-- a. 尝试从旧主库拉取缺失的binlog（如果主库还能SSH连接）
-- b. 从最新的从库拉取差异binlog
-- c. 应用差异binlog到新主库

-- 差异数据恢复流程：
-- 从库A（最新）：gtid 1-100
-- 从库B：gtid 1-95
-- 新主库选择从库A

-- 从库B需要应用gtid 96-100的事务
-- MHA会从从库A的relay log中提取这些事务并应用到从库B
```

**4. 切换步骤**
```sql
-- 步骤1：确认主库真的宕机（多次检测）

-- 步骤2：选择新主库（假设选择slave1）

-- 步骤3：应用差异日志到新主库
-- mysqlbinlog差异日志 | mysql -h新主库

-- 步骤4：将新主库设置为可写
-- 在slave1执行：
STOP SLAVE;
RESET SLAVE ALL;
SET GLOBAL read_only = 0;
SET GLOBAL super_read_only = 0;

-- 步骤5：将其他从库指向新主库
-- 在slave2, slave3执行：
STOP SLAVE;
CHANGE MASTER TO
  MASTER_HOST = 'slave1_ip',
  MASTER_AUTO_POSITION = 1;  -- GTID模式
START SLAVE;

-- 步骤6：更新VIP（虚拟IP）
-- 将VIP从旧主库漂移到新主库
```

**5. 应用层如何感知切换**

**方案1：VIP漂移**
```bash
# 应用连接VIP：192.168.1.200
# MHA切换时，VIP自动漂移到新主库
# 应用无感知（短暂连接失败后重连即可）

# VIP漂移脚本（MHA调用）
# master_ip_failover_script
ip addr del 192.168.1.200/24 dev eth0  # 旧主库
ip addr add 192.168.1.200/24 dev eth0  # 新主库
```

**方案2：DNS更新**
```bash
# 更新DNS记录，将db-master域名指向新主库IP
```

**方案3：配置中心**
```python
# 应用从配置中心获取主库地址
# MHA切换后更新配置中心
# 应用定期刷新配置或接收配置变更通知

# 示例：使用etcd
etcdctl set /mysql/master "新主库IP:3306"
```

**方案4：数据库代理**
```
应用 -> ProxySQL/MaxScale -> MySQL集群
代理层感知主库切换，应用无需变更
```

### 14. MGR集群（MySQL Group Replication）

```sql
-- 查看MGR集群状态
SELECT * FROM performance_schema.replication_group_members;
```

**输出示例**：
```
+---------------------------+-------------+-------------+--------------+
| CHANNEL_NAME              | MEMBER_ID   | MEMBER_HOST | MEMBER_STATE |
+---------------------------+-------------+-------------+--------------+
| group_replication_applier | uuid1       | node1:3306  | ONLINE       |
| group_replication_applier | uuid2       | node2:3306  | ONLINE       |
| group_replication_applier | uuid3       | node3:3306  | ONLINE       |
+---------------------------+-------------+-------------+--------------+
```

**查看MGR配置**：
```sql
SHOW VARIABLES LIKE 'group_replication%';
```

**重要配置项**：
```
group_replication_group_name: 组复制UUID
group_replication_start_on_boot: 是否自启动
group_replication_bootstrap_group: 是否引导组（仅首个节点）
group_replication_single_primary_mode: 单主模式（ON）或多主模式（OFF）
```

**任务解答**：

**1. MGR单主模式和多主模式的区别**

| 特性 | 单主模式 | 多主模式 |
|------|----------|----------|
| 写入节点 | 仅主节点可写，其他只读 | 所有节点可写 |
| 性能 | 写入集中，性能高 | 写入分散，可能有冲突检测开销 |
| 一致性 | 强一致性 | 强一致性，但有冲突风险 |
| 故障切换 | 自动选举新主节点 | 无需切换，所有节点可写 |
| 适用场景 | 大部分应用场景 | 需要多点写入的场景 |

**2. MGR如何保证数据一致性**

```
基于Paxos协议的组复制：
1. 事务在本地执行并生成binlog
2. 将事务广播到组内所有成员
3. 所有成员验证事务（冲突检测）
4. 达成一致后，所有成员应用事务
5. 返回客户端提交成功

冲突检测：
- 基于行级别的写集合（writeset）
- 检查是否有并发事务修改相同行
- 冲突事务会回滚并报错
```

**3. 如何处理MGR脑裂问题**

```sql
-- 脑裂场景：网络分区导致集群分裂

-- 预防措施1：设置合理的group_replication_member_expel_timeout
-- 成员超时踢出时间
SET GLOBAL group_replication_member_expel_timeout = 5;  -- 5秒

-- 预防措施2：使用奇数个节点（3、5、7）
-- 避免网络分区后无法达成多数派

-- 预防措施3：配置仲裁节点（Arbitrator）
-- 不存储数据，仅参与投票

-- 脑裂检测：
SELECT
    MEMBER_HOST,
    MEMBER_STATE,
    IF(MEMBER_ROLE='PRIMARY', 'PRIMARY', 'SECONDARY') AS ROLE
FROM performance_schema.replication_group_members;

-- 如果发现多个PRIMARY，说明发生脑裂

-- 恢复措施：
-- 1. 识别拥有最新数据的分区（通过GTID或binlog位置）
-- 2. 停止少数派分区的组复制
STOP GROUP_REPLICATION;

-- 3. 在多数派分区重新引导组
-- 在多数派的一个节点执行
SET GLOBAL group_replication_force_members = 'node1:3306,node2:3306';

-- 4. 重新加入少数派节点
-- 在少数派节点执行
START GROUP_REPLICATION;
```

## 九、复制过滤

### 15. 配置复制过滤规则

**从库my.cnf配置**：
```ini
[mysqld]
# 只复制特定数据库
replicate-do-db = study_db
replicate-do-db = ecommerce_db

# 忽略特定数据库
replicate-ignore-db = test
replicate-ignore-db = tmp_db

# 只复制特定表
replicate-do-table = study_db.orders
replicate-do-table = study_db.users

# 通配符匹配表
replicate-wild-do-table = study_db.order_%
replicate-wild-do-table = study_db.product_%

# 忽略特定表
replicate-ignore-table = study_db.logs
replicate-ignore-table = study_db.tmp_table

# 通配符忽略
replicate-wild-ignore-table = %.tmp_%
```

**动态配置（MySQL 8.0+）**：
```sql
-- 查看当前过滤规则
SHOW SLAVE STATUS\G
-- 查看：Replicate_Do_DB, Replicate_Ignore_DB等字段

-- 动态修改（需要CHANGE REPLICATION FILTER权限）
STOP SLAVE SQL_THREAD;

CHANGE REPLICATION FILTER
  REPLICATE_DO_DB = (study_db, ecommerce_db),
  REPLICATE_IGNORE_TABLE = (study_db.logs, study_db.tmp_data);

START SLAVE SQL_THREAD;
```

**任务解答**：

**1. 使用复制过滤的风险**

- **binlog位置错乱**：主库的binlog位置和从库执行位置不匹配
- **数据完整性**：忽略的表可能被其他表外键引用
- **切换困难**：主从切换时，从库数据不完整无法提升为主库
- **维护复杂**：规则配置错误导致意外的数据丢失
- **不支持GTID**：某些过滤规则在GTID模式下不工作

**示例风险场景**：
```sql
-- 配置：replicate-ignore-table = study_db.logs

-- 主库执行（单个事务）：
BEGIN;
INSERT INTO orders VALUES (...);
INSERT INTO logs VALUES (...);  -- 被过滤
COMMIT;

-- 从库只执行了一半事务，数据不一致风险
```

**2. 为什么不推荐在生产环境使用表级过滤**

- **binlog是语句级/行级，过滤是表级** - 不匹配导致问题
- **跨表事务被拆分** - 事务完整性无法保证
- **跨库操作混乱** - USE db1; INSERT INTO db2.table 可能被错误过滤
- **运维负担** - 规则维护困难，容易出错
- **故障恢复困难** - 无法通过binlog完整恢复数据

**推荐做法**：
```
- 垂直拆分：不同业务使用不同主从集群
- 库级过滤：仅在binlog层面做库级别过滤
- 从库用途明确：如果从库仅用于查询，不做过滤，保持数据完整
```

## 十、综合实战

### 16. 主从切换演练

**完整流程**：

```sql
-- 【前提】当前架构
-- Master（主库）：192.168.1.100
-- Slave1（从库1）：192.168.1.101
-- Slave2（从库2）：192.168.1.102

-- 【场景】主库故障，提升Slave1为新主库

-- ========== 步骤1：在Slave1上停止复制 ==========
-- 在Slave1执行
STOP SLAVE;

-- ========== 步骤2：确认Slave1数据完整性 ==========
-- 在Slave1执行
SHOW SLAVE STATUS\G

-- 关键检查项：
-- Slave_IO_Running: Yes/No（故障时可能是No）
-- Slave_SQL_Running: Yes
-- Seconds_Behind_Master: 0（确保已同步所有数据）
-- Executed_Gtid_Set: 记录已执行的GTID

-- 检查数据一致性
SELECT COUNT(*) FROM orders;
SELECT MAX(id) FROM orders;

-- 等待SQL线程执行完所有relay log
-- 如果Seconds_Behind_Master > 0，等待其变为0

-- ========== 步骤3：将Slave1设置为可写 ==========
-- 在Slave1执行
RESET SLAVE ALL;  -- 清除主从复制配置

SET GLOBAL read_only = 0;
SET GLOBAL super_read_only = 0;

-- 验证
SHOW VARIABLES LIKE '%read_only%';

-- 开启binlog（如果之前未开启）
-- 已在my.cnf配置则跳过

-- ========== 步骤4：获取Slave1的binlog位置（用于其他从库） ==========
-- 在Slave1执行
FLUSH LOGS;  -- 轮转binlog，便于管理
SHOW MASTER STATUS;

-- 记录输出，例如：
-- File: mysql-bin.000005
-- Position: 154

-- ========== 步骤5：配置Slave2指向新主库Slave1 ==========
-- 在Slave2执行
STOP SLAVE;

-- 方式1：使用binlog位置（传统方式）
CHANGE MASTER TO
  MASTER_HOST = '192.168.1.101',  -- Slave1的IP
  MASTER_PORT = 3306,
  MASTER_USER = 'repl_user',
  MASTER_PASSWORD = 'repl_password',
  MASTER_LOG_FILE = 'mysql-bin.000005',  -- 步骤4记录的
  MASTER_LOG_POS = 154;

-- 方式2：使用GTID（推荐）
CHANGE MASTER TO
  MASTER_HOST = '192.168.1.101',
  MASTER_PORT = 3306,
  MASTER_USER = 'repl_user',
  MASTER_PASSWORD = 'repl_password',
  MASTER_AUTO_POSITION = 1;

START SLAVE;

-- 验证
SHOW SLAVE STATUS\G
-- 检查Slave_IO_Running和Slave_SQL_Running都是Yes

-- ========== 步骤6：应用层切换数据源 ==========
-- 方式1：VIP漂移（推荐）
-- 在Slave1（新主库）执行（需要root权限）
ip addr add 192.168.1.200/24 dev eth0

-- 在旧主库执行（如果还能连接）
ip addr del 192.168.1.200/24 dev eth0

-- 应用配置：jdbc:mysql://192.168.1.200:3306/study_db
-- VIP自动漂移到Slave1，应用无需修改配置

-- 方式2：修改应用配置
-- 应用配置文件或配置中心更新：
-- db.master.host = 192.168.1.101

-- 方式3：DNS更新
-- 更新db-master.example.com的A记录，指向192.168.1.101

-- ========== 步骤7：验证新主从架构 ==========
-- 在新主库Slave1写入数据
INSERT INTO orders (user_id, total_amount, status)
VALUES (1, 100.00, 'pending');

-- 在从库Slave2查询，验证数据已同步
SELECT * FROM orders ORDER BY id DESC LIMIT 1;

-- ========== 步骤8：处理旧主库（如果能恢复） ==========
-- 如果旧主库修复后，将其作为从库加入集群

-- 在旧主库执行
-- 设置只读
SET GLOBAL read_only = 1;
SET GLOBAL super_read_only = 1;

-- 配置为Slave1的从库
CHANGE MASTER TO
  MASTER_HOST = '192.168.1.101',
  MASTER_PORT = 3306,
  MASTER_USER = 'repl_user',
  MASTER_PASSWORD = 'repl_password',
  MASTER_AUTO_POSITION = 1;

START SLAVE;
```

**切换检查清单**：
```
□ Slave1数据完全同步（Seconds_Behind_Master = 0）
□ Slave1设置为可写（read_only = 0）
□ Slave2成功连接到Slave1
□ Slave2复制状态正常（IO和SQL线程都是Yes）
□ 应用层已切换到新主库
□ 新主库可正常写入
□ 从库能同步新主库的数据
□ 监控告警已更新
□ 文档已记录切换过程
```

### 17. 监控告警设计

**完整的监控告警表**：

| 指标 | 监控SQL/命令 | 告警阈值 | 处理方案 |
|------|-------------|----------|----------|
| 同步延迟 | `SHOW SLAVE STATUS\G` 查看`Seconds_Behind_Master` | >10秒警告，>60秒严重 | 1. 检查从库慢查询<br>2. 检查网络带宽<br>3. 检查是否有大事务<br>4. 考虑并行复制 |
| IO线程状态 | `SHOW SLAVE STATUS\G` 查看`Slave_IO_Running` | = No | 1. 检查主库是否可达<br>2. 检查复制用户权限<br>3. 检查网络连接<br>4. 查看`Last_IO_Error` |
| SQL线程状态 | `SHOW SLAVE STATUS\G` 查看`Slave_SQL_Running` | = No | 1. 查看`Last_SQL_Error`<br>2. 检查数据冲突（主键重复等）<br>3. 手动修复数据<br>4. 必要时重建从库 |
| 半同步降级 | `SHOW STATUS LIKE 'Rpl_semi_sync_master_status'` | = OFF | 1. 检查从库状态<br>2. 检查网络延迟<br>3. 检查`Rpl_semi_sync_master_no_tx`增长 |
| Binlog磁盘空间 | `SELECT @@datadir; df -h` | >80%使用率 | 1. 清理过期binlog<br>2. 检查binlog过期配置<br>3. 扩容磁盘 |
| 复制延迟事件 | `SELECT COUNT(*) FROM performance_schema.replication_applier_status_by_worker WHERE LAST_ERROR_NUMBER != 0` | >0 | 查看具体错误，针对性处理 |
| 主库binlog生成速度 | `SHOW BINARY LOGS` 计算增长 | >10GB/小时 | 1. 检查是否有大批量操作<br>2. 评估从库是否能跟上<br>3. 考虑限流 |
| GTID gaps | 比较主从`gtid_executed` | 存在缺失GTID | 数据不一致，需要重建从库 |

**监控脚本示例**：
```bash
#!/bin/bash
# 主从复制监控脚本

MYSQL_USER="monitor"
MYSQL_PASS="password"
MYSQL_CMD="mysql -u$MYSQL_USER -p$MYSQL_PASS -e"

# 1. 检查IO线程
IO_RUNNING=$($MYSQL_CMD "SHOW SLAVE STATUS\G" | grep "Slave_IO_Running:" | awk '{print $2}')
if [ "$IO_RUNNING" != "Yes" ]; then
    echo "CRITICAL: IO线程未运行"
    # 发送告警
    curl -X POST "http://alert-api/send" -d '{"msg":"MySQL Slave IO线程停止"}'
fi

# 2. 检查SQL线程
SQL_RUNNING=$($MYSQL_CMD "SHOW SLAVE STATUS\G" | grep "Slave_SQL_Running:" | awk '{print $2}')
if [ "$SQL_RUNNING" != "Yes" ]; then
    echo "CRITICAL: SQL线程未运行"
    LAST_ERROR=$($MYSQL_CMD "SHOW SLAVE STATUS\G" | grep "Last_SQL_Error:" | cut -d: -f2-)
    curl -X POST "http://alert-api/send" -d "{\"msg\":\"MySQL Slave SQL线程停止: $LAST_ERROR\"}"
fi

# 3. 检查延迟
DELAY=$($MYSQL_CMD "SHOW SLAVE STATUS\G" | grep "Seconds_Behind_Master:" | awk '{print $2}')
if [ "$DELAY" != "NULL" ] && [ $DELAY -gt 10 ]; then
    echo "WARNING: 主从延迟${DELAY}秒"
    curl -X POST "http://alert-api/send" -d "{\"msg\":\"MySQL主从延迟${DELAY}秒\"}"
fi

echo "监控完成: IO=$IO_RUNNING, SQL=$SQL_RUNNING, Delay=${DELAY}s"
```

**Prometheus监控指标**（使用mysqld_exporter）：
```yaml
# 告警规则示例
groups:
- name: mysql_replication
  rules:
  - alert: MySQLSlaveIOThreadNotRunning
    expr: mysql_slave_status_slave_io_running == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "MySQL Slave IO线程未运行"

  - alert: MySQLSlaveSQLThreadNotRunning
    expr: mysql_slave_status_slave_sql_running == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "MySQL Slave SQL线程未运行"

  - alert: MySQLReplicationLag
    expr: mysql_slave_status_seconds_behind_master > 60
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "MySQL主从延迟超过60秒"
```

### 18. 数据一致性校验

**使用pt-table-checksum**：

```bash
# 安装percona-toolkit
# Ubuntu/Debian
apt-get install percona-toolkit

# CentOS/RHEL
yum install percona-toolkit

# 执行校验
pt-table-checksum \
  --host=192.168.1.100 \  # 主库IP
  --port=3306 \
  --user=checksum_user \
  --password=checksum_pass \
  --databases=study_db \
  --tables=orders,users,products \
  --replicate=percona.checksums \  # 校验结果表
  --no-check-binlog-format \
  --chunk-size=1000 \  # 每次检查1000行
  --max-load="Threads_running=50" \  # 负载保护
  --recursion-method=dsn=h=localhost,D=percona,t=dsns \
  --quiet

# 参数说明：
# --replicate: 校验结果存储表（会自动创建）
# --chunk-size: 分块大小，避免锁表
# --max-load: 负载阈值，超过则暂停
```

**查看不一致的表**：
```sql
-- 在主库查询
SELECT
    db,
    tbl AS 表名,
    chunk AS 数据块,
    this_cnt AS 从库行数,
    master_cnt AS 主库行数,
    this_crc AS 从库CRC,
    master_crc AS 主库CRC
FROM percona.checksums
WHERE (
    master_cnt <> this_cnt  -- 行数不一致
    OR master_crc <> this_crc  -- 校验和不一致
    OR this_crc IS NULL  -- 从库未校验
)
ORDER BY db, tbl, chunk;
```

**任务解答**：

**1. 发现数据不一致后如何修复？**

**方法1：使用pt-table-sync修复**
```bash
# 干运行（仅查看差异，不修复）
pt-table-sync \
  --print \
  --replicate=percona.checksums \
  h=192.168.1.100,D=study_db \
  h=192.168.1.101

# 真正执行修复
pt-table-sync \
  --execute \
  --replicate=percona.checksums \
  --sync-to-master \  # 以主库为准
  h=192.168.1.101  # 从库IP

# 参数说明：
# --print: 只打印SQL不执行
# --execute: 真正执行修复
# --sync-to-master: 以主库数据为准
```

**方法2：重新导入不一致的表**
```bash
# 在主库导出
mysqldump -h 192.168.1.100 -uroot -p \
  --single-transaction \
  --no-create-info \  # 不包含建表语句
  study_db orders > orders_data.sql

# 在从库停止复制
mysql -h 192.168.1.101 -uroot -p -e "STOP SLAVE;"

# 清空从库表并导入
mysql -h 192.168.1.101 -uroot -p study_db -e "TRUNCATE TABLE orders;"
mysql -h 192.168.1.101 -uroot -p study_db < orders_data.sql

# 重新启动复制
mysql -h 192.168.1.101 -uroot -p -e "START SLAVE;"
```

**方法3：重建从库**（最彻底）
```bash
# 参考16题的重建从库流程
```

**2. 如何避免校验时对业务的影响？**

**策略1：限制资源使用**
```bash
pt-table-checksum \
  --chunk-size=500 \  # 减小分块大小
  --chunk-time=0.5 \  # 每个块最多0.5秒
  --max-load="Threads_running=25,Threads_connected=100" \  # 负载保护
  --check-interval=1 \  # 每秒检查一次负载
  --pause-file=/tmp/pt-checksum-pause  # 创建此文件可暂停
  ...
```

**策略2：在业务低峰期执行**
```bash
# 凌晨2-6点执行
0 2 * * * /usr/bin/pt-table-checksum ... >> /var/log/pt-checksum.log 2>&1
```

**策略3：在从库执行**
```bash
# 虽然checksum需要在主库运行，但可以：
# 1. 使用延迟从库或备库执行
# 2. 校验结果会同步到所有从库
# 3. 主库压力较小
```

**策略4：分批次执行**
```bash
# 今天校验一部分表
pt-table-checksum --tables=orders,users ...

# 明天校验另一部分表
pt-table-checksum --tables=products,reviews ...
```

**策略5：监控和熔断**
```bash
# 编写监控脚本
while true; do
    LOAD=$(mysql -e "SHOW GLOBAL STATUS LIKE 'Threads_running'" | awk 'NR==2{print $2}')
    if [ $LOAD -gt 50 ]; then
        touch /tmp/pt-checksum-pause  # 暂停校验
        echo "负载过高，暂停校验"
        sleep 60
    else
        rm -f /tmp/pt-checksum-pause  # 恢复校验
    fi
    sleep 5
done
```

## 总结

主从复制和集群是MySQL高可用的基础，需要重点掌握：
1. **主从配置**：正确配置server-id、binlog、复制用户
2. **状态监控**：持续监控复制状态和延迟
3. **故障处理**：快速诊断和修复复制问题
4. **GTID**：简化运维，推荐生产环境使用
5. **高可用方案**：MHA、MGR等，根据业务选择
6. **读写分离**：合理设计路由策略，平衡性能和一致性
7. **数据一致性**：定期校验，及时发现问题

**学习建议**：
- 在测试环境搭建主从架构，实践各种场景
- 模拟故障进行切换演练
- 熟练使用监控工具和脚本
- 理解各种高可用方案的适用场景
