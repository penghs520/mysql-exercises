# 10 - 分库分表 - 参考答案

## 一、垂直拆分

### 1. 垂直分库设计

**拆分依据**：
- 业务边界清晰
- 减少跨库事务
- 便于独立扩展
- 不同业务的访问特征不同

**创建数据库**：

```sql
-- 用户库（高频读写，需要高可用）
CREATE DATABASE user_db
DEFAULT CHARACTER SET utf8mb4
DEFAULT COLLATE utf8mb4_unicode_ci;

-- 商品库（读多写少，需要读扩展）
CREATE DATABASE product_db
DEFAULT CHARACTER SET utf8mb4
DEFAULT COLLATE utf8mb4_unicode_ci;

-- 订单库（写入频繁，数据量大）
CREATE DATABASE order_db
DEFAULT CHARACTER SET utf8mb4
DEFAULT COLLATE utf8mb4_unicode_ci;

-- 评价库（独立业务，可分离）
CREATE DATABASE review_db
DEFAULT CHARACTER SET utf8mb4
DEFAULT COLLATE utf8mb4_unicode_ci;
```

**拆分理由**：

| 数据库 | 表 | 拆分理由 |
|--------|-----|----------|
| **user_db** | users, user_addresses | 用户体系独立，高频访问，需要高性能和高可用 |
| **product_db** | categories, products, product_skus | 商品数据读多写少，可独立做读优化（如缓存、搜索引擎） |
| **order_db** | orders, order_items, payments | 订单是核心业务，写入频繁，数据增长快，需要分表 |
| **review_db** | product_reviews | 评价业务相对独立，可异步处理，对一致性要求低 |

**迁移表结构**：

```sql
-- 1. 迁移用户相关表到user_db
USE user_db;

CREATE TABLE users LIKE study_db.users;
CREATE TABLE user_addresses LIKE study_db.user_addresses;

INSERT INTO users SELECT * FROM study_db.users;
INSERT INTO user_addresses SELECT * FROM study_db.user_addresses;

-- 2. 迁移商品相关表到product_db
USE product_db;

CREATE TABLE categories LIKE study_db.categories;
CREATE TABLE products LIKE study_db.products;
CREATE TABLE product_skus LIKE study_db.product_skus;

INSERT INTO categories SELECT * FROM study_db.categories;
INSERT INTO products SELECT * FROM study_db.products;
INSERT INTO product_skus SELECT * FROM study_db.product_skus;

-- 3. 迁移订单相关表到order_db
USE order_db;

CREATE TABLE orders LIKE study_db.orders;
CREATE TABLE order_items LIKE study_db.order_items;
CREATE TABLE payments LIKE study_db.payments;

INSERT INTO orders SELECT * FROM study_db.orders;
INSERT INTO order_items SELECT * FROM study_db.order_items;
INSERT INTO payments SELECT * FROM study_db.payments;

-- 4. 迁移评价表到review_db
USE review_db;

CREATE TABLE product_reviews LIKE study_db.product_reviews;

INSERT INTO product_reviews SELECT * FROM study_db.product_reviews;
```

**优点**：
- 业务隔离，互不影响
- 便于团队分工（不同团队维护不同数据库）
- 可针对性优化（如商品库做缓存，订单库分表）
- 降低单库压力

**缺点**：
- 无法使用JOIN跨库查询
- 分布式事务复杂
- 数据一致性维护困难
- 运维成本增加

### 2. 垂直分表设计

**原users表结构分析**：

```sql
-- 字段使用频率分析
-- 高频字段：id, username, email, phone（登录、身份验证）
-- 低频字段：avatar_url, gender, birth_date, registration_ip, last_login_ip, last_login_at
```

**拆分后的表结构**：

```sql
-- users_basic：基本信息（高频访问）
CREATE TABLE users_basic (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    username VARCHAR(50) NOT NULL UNIQUE COMMENT '用户名',
    email VARCHAR(100) NOT NULL UNIQUE COMMENT '邮箱',
    password_hash VARCHAR(255) NOT NULL COMMENT '密码哈希',
    phone VARCHAR(20) UNIQUE COMMENT '手机号',
    is_active TINYINT(1) DEFAULT 1 COMMENT '是否激活',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    INDEX idx_username (username),
    INDEX idx_email (email),
    INDEX idx_phone (phone)
) ENGINE=InnoDB COMMENT='用户基本信息表';

-- users_extra：扩展信息（低频访问）
CREATE TABLE users_extra (
    user_id BIGINT PRIMARY KEY COMMENT '用户ID，外键关联users_basic.id',
    avatar_url VARCHAR(500) COMMENT '头像URL',
    gender ENUM('male','female','other') COMMENT '性别',
    birth_date DATE COMMENT '生日',
    registration_ip VARCHAR(50) COMMENT '注册IP',
    last_login_ip VARCHAR(50) COMMENT '最后登录IP',
    last_login_at TIMESTAMP COMMENT '最后登录时间',
    bio TEXT COMMENT '个人简介',
    preferences JSON COMMENT '用户偏好设置',
    INDEX idx_last_login (last_login_at),
    FOREIGN KEY (user_id) REFERENCES users_basic(id) ON DELETE CASCADE
) ENGINE=InnoDB COMMENT='用户扩展信息表';
```

**拆分理由**：

1. **提升查询性能**：
   - 登录只需查users_basic（数据量小，缓存友好）
   - 减少单表字段数，减小行大小
   - 提升索引效率

2. **冷热数据分离**：
   - 热数据（基本信息）常驻内存
   - 冷数据（扩展信息）按需加载

3. **节省存储**：
   - 如果很多用户不填写扩展信息，users_extra行数 < users_basic
   - 减少NULL值存储

4. **独立扩展**：
   - 扩展信息可以使用不同的存储引擎（如列式存储）
   - 便于添加新字段而不影响核心表

**查询示例**：

```sql
-- 登录查询（仅查基本表）
SELECT id, username, password_hash, is_active
FROM users_basic
WHERE email = 'user@example.com';

-- 用户资料页面（需要JOIN）
SELECT
    b.id, b.username, b.email, b.phone,
    e.avatar_url, e.gender, e.birth_date, e.bio
FROM users_basic b
LEFT JOIN users_extra e ON b.id = e.user_id
WHERE b.id = 123;

-- 统计活跃用户（仅查基本表）
SELECT COUNT(*) FROM users_basic WHERE is_active = 1;
```

## 二、水平分库分表策略

### 3. 分片键选择

**对比分析**：

| 分片键 | 优点 | 缺点 | 适用场景 |
|--------|------|------|----------|
| **user_id** | 同一用户数据在同一分片，利于查询 | 按订单ID查询需要遍历所有分片 | C端用户查询自己订单为主 |
| **order_id** | 按订单ID查询快，数据分布均匀 | 同一用户订单分散，聚合查询困难 | B端管理后台，按订单维度查询 |
| **created_at** | 时间范围查询快，易于归档 | 最新分片压力大（热点），扩容困难 | 日志、流水类数据 |

**详细分析**：

**方案1：user_id分片（推荐）**

优点：
```sql
-- 查询某用户的所有订单（单分片查询）
SELECT * FROM orders_X  -- X = user_id % 分片数
WHERE user_id = 123
ORDER BY created_at DESC;

-- 优势：
-- 1. 数据locality好，用户相关数据在一起
-- 2. 大部分查询是用户查自己的订单
-- 3. 避免跨分片查询
-- 4. 扩展性好，用户分布相对均匀
```

缺点：
```sql
-- 根据订单ID查询（需要遍历所有分片）
SELECT * FROM orders_0 WHERE id = 10001
UNION ALL
SELECT * FROM orders_1 WHERE id = 10001
UNION ALL
SELECT * FROM orders_2 WHERE id = 10001
UNION ALL
SELECT * FROM orders_3 WHERE id = 10001;

-- 解决方案：引入路由表（见后续题目）
```

**方案2：order_id分片**

优点：
```sql
-- 按订单ID查询（单分片查询）
SELECT * FROM orders_X  -- X = order_id % 分片数
WHERE id = 10001;

-- 数据分布均匀（如果订单ID是递增的）
```

缺点：
```sql
-- 查询某用户的所有订单（跨所有分片）
SELECT * FROM orders_0 WHERE user_id = 123
UNION ALL
SELECT * FROM orders_1 WHERE user_id = 123
UNION ALL
...;

-- 性能差，不适合用户自查订单的场景
```

**方案3：created_at分片**

优点：
```sql
-- 查询某时间段订单（少量分片）
SELECT * FROM orders_202401  -- 按月分片
WHERE created_at BETWEEN '2024-01-01' AND '2024-01-31';

-- 易于归档历史数据
DROP TABLE orders_202301;  -- 删除2023年1月的订单
```

缺点：
```
-- 热点问题严重
-- 当前月的表承担所有写入
-- 历史月的表几乎不写入
-- 无法利用多个分片的写入能力

-- 扩容困难
-- 已经按时间固定分片，无法调整
```

**推荐方案：user_id + 路由表**

```sql
-- 主表：按user_id分片
-- orders_0, orders_1, orders_2, orders_3

-- 路由表：order_id -> user_id, shard_index
CREATE TABLE order_route (
    order_id BIGINT PRIMARY KEY,
    user_id BIGINT NOT NULL,
    shard_index TINYINT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_user_id (user_id),
    INDEX idx_created_at (created_at)
) ENGINE=InnoDB;

-- 查询流程：
-- 1. 根据user_id直接查询订单（单分片）
SELECT * FROM orders_2 WHERE user_id = 123;

-- 2. 根据order_id查询（先查路由表，再查分片）
-- 步骤1：查路由表
SELECT shard_index FROM order_route WHERE order_id = 10001;  -- 返回2
-- 步骤2：查对应分片
SELECT * FROM orders_2 WHERE id = 10001;
```

### 4. 分片算法设计

**算法对比**：

**方案1：取模分片（最常用）**

```python
def get_table_name(user_id, shard_count=4):
    """
    取模分片算法
    优点：实现简单，数据分布均匀
    缺点：扩容需要数据迁移
    """
    table_index = user_id % shard_count
    return f"orders_{table_index}"

# 示例
print(get_table_name(100, 4))  # orders_0 (100 % 4 = 0)
print(get_table_name(101, 4))  # orders_1 (101 % 4 = 1)
print(get_table_name(102, 4))  # orders_2
print(get_table_name(103, 4))  # orders_3
print(get_table_name(104, 4))  # orders_0
```

优点：
- 实现简单
- 数据分布均匀
- 性能好（取模运算快）

缺点：
- 扩容困难（4->8需要迁移50%数据）
- 缩容几乎不可能

**方案2：范围分片**

```python
def get_table_name_by_range(user_id):
    """
    范围分片算法
    优点：扩容相对简单
    缺点：数据分布不均（新用户多的分片压力大）
    """
    if user_id <= 250:
        return "orders_0"
    elif user_id <= 500:
        return "orders_1"
    elif user_id <= 750:
        return "orders_2"
    else:
        return "orders_3"

# 示例
print(get_table_name_by_range(100))   # orders_0
print(get_table_name_by_range(300))   # orders_1
print(get_table_name_by_range(600))   # orders_2
print(get_table_name_by_range(1000))  # orders_3
```

优点：
- 扩容时只需添加新分片，不迁移旧数据
- 范围查询友好

缺点：
- 数据分布不均（新用户集中在最后的分片）
- 需要维护范围映射表

**方案3：一致性Hash**

```python
import hashlib

def consistent_hash(user_id, shard_count=4):
    """
    一致性Hash算法
    优点：扩容时数据迁移量少（约1/n）
    缺点：实现复杂，数据分布可能不均
    """
    # 计算hash值
    hash_value = int(hashlib.md5(str(user_id).encode()).hexdigest(), 16)

    # 映射到分片
    table_index = hash_value % shard_count
    return f"orders_{table_index}"

# 示例
print(consistent_hash(100, 4))  # orders_?（MD5哈希后取模）
print(consistent_hash(101, 4))
```

优点：
- 扩容时迁移数据量少（从N分片扩到N+1，平均迁移1/(N+1)的数据）
- 适合动态扩容场景

缺点：
- 实现复杂（需要虚拟节点保证均匀性）
- 调试困难（hash值不直观）

**对比总结**：

| 算法 | 数据分布 | 扩容难度 | 迁移量（4->8） | 适用场景 |
|------|----------|----------|----------------|----------|
| 取模 | 均匀 | 困难 | 50% | 数据量可预估，不频繁扩容 |
| 范围 | 不均 | 简单 | 0% | 有明显范围特征，如时间 |
| 一致性Hash | 较均匀 | 中等 | 12.5% | 频繁扩容，分布式系统 |

**扩容数据迁移示例（取模：4->8）**：

```sql
-- 原来4张表，扩容到8张表

-- user_id=100，原来在orders_0（100%4=0），扩容后在orders_4（100%8=4）
-- 需要迁移

-- user_id=104，原来在orders_0（104%4=0），扩容后在orders_0（104%8=0）
-- 不需要迁移

-- 迁移规律：
-- orders_0 -> 一半留在orders_0，一半迁移到orders_4
-- orders_1 -> 一半留在orders_1，一半迁移到orders_5
-- orders_2 -> 一半留在orders_2，一半迁移到orders_6
-- orders_3 -> 一半留在orders_3，一半迁移到orders_7

-- 迁移SQL示例
-- 从orders_0迁移到orders_4
INSERT INTO orders_4
SELECT * FROM orders_0
WHERE user_id % 8 = 4;

DELETE FROM orders_0 WHERE user_id % 8 = 4;
```

**双倍扩容的好处**：
- 每个旧分片只需迁移到一个新分片
- 迁移逻辑简单（取模判断）
- 可并行迁移

## 三、分表实战

### 5. 创建分表

```sql
-- 查看原orders表结构
SHOW CREATE TABLE orders\G

-- 方法1：使用LIKE快速创建（推荐）
CREATE TABLE orders_0 LIKE orders;
CREATE TABLE orders_1 LIKE orders;
CREATE TABLE orders_2 LIKE orders;
CREATE TABLE orders_3 LIKE orders;

-- 方法2：完整定义表结构
CREATE TABLE orders_0 (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    user_id BIGINT NOT NULL COMMENT '用户ID',
    total_amount DECIMAL(10,2) NOT NULL COMMENT '订单总金额',
    status ENUM('pending','paid','shipped','completed','cancelled') DEFAULT 'pending' COMMENT '订单状态',
    payment_method VARCHAR(50) COMMENT '支付方式',
    shipping_address_id BIGINT COMMENT '收货地址ID',
    remark TEXT COMMENT '备注',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

    INDEX idx_user_id (user_id),
    INDEX idx_status (status),
    INDEX idx_created_at (created_at),
    INDEX idx_user_created (user_id, created_at)
) ENGINE=InnoDB COMMENT='订单表_分片0';

-- 同样创建orders_1, orders_2, orders_3

-- 验证表结构
SHOW TABLES LIKE 'orders_%';
DESC orders_0;
```

**注意事项**：
1. **AUTO_INCREMENT独立**：每个分表有独立的自增序列，不能用作全局唯一ID
2. **索引一致**：所有分表索引结构要一致
3. **分区键索引**：user_id必须有索引

### 6. 数据迁移

```sql
-- 数据迁移到分表
-- 方法1：按分片逻辑直接INSERT

-- 迁移到orders_0 (user_id % 4 = 0)
INSERT INTO orders_0
SELECT * FROM orders
WHERE user_id % 4 = 0;

-- 迁移到orders_1
INSERT INTO orders_1
SELECT * FROM orders
WHERE user_id % 4 = 1;

-- 迁移到orders_2
INSERT INTO orders_2
SELECT * FROM orders
WHERE user_id % 4 = 2;

-- 迁移到orders_3
INSERT INTO orders_3
SELECT * FROM orders
WHERE user_id % 4 = 3;

-- 方法2：分批迁移（大表推荐，避免锁表）
-- 每次迁移1000条
SET @offset = 0;
SET @batch_size = 1000;

WHILE @offset < (SELECT COUNT(*) FROM orders WHERE user_id % 4 = 0) DO
    INSERT INTO orders_0
    SELECT * FROM orders
    WHERE user_id % 4 = 0
    LIMIT @offset, @batch_size;

    SET @offset = @offset + @batch_size;
END WHILE;

-- 验证数据完整性
SELECT COUNT(*) AS original_count FROM orders;

SELECT
    (SELECT COUNT(*) FROM orders_0) +
    (SELECT COUNT(*) FROM orders_1) +
    (SELECT COUNT(*) FROM orders_2) +
    (SELECT COUNT(*) FROM orders_3) AS sharded_count;

-- 两者应该相等

-- 验证数据分布
SELECT
    'orders_0' AS shard_name,
    COUNT(*) AS row_count,
    MIN(user_id) AS min_user_id,
    MAX(user_id) AS max_user_id
FROM orders_0
UNION ALL
SELECT 'orders_1', COUNT(*), MIN(user_id), MAX(user_id) FROM orders_1
UNION ALL
SELECT 'orders_2', COUNT(*), MIN(user_id), MAX(user_id) FROM orders_2
UNION ALL
SELECT 'orders_3', COUNT(*), MIN(user_id), MAX(user_id) FROM orders_3;

-- 验证分片逻辑（抽样检查）
SELECT
    user_id,
    user_id % 4 AS expected_shard,
    'orders_0' AS actual_shard
FROM orders_0
WHERE user_id % 4 != 0
LIMIT 10;
-- 应该返回0行（没有分片错误的数据）
```

### 7. 分表查询

**需求1：查询某用户的所有订单**

```sql
-- 已知user_id，可以直接定位分表
SET @user_id = 123;
SET @table_index = @user_id % 4;  -- 计算分表索引

-- 应用层根据table_index选择表
-- 假设user_id=123, 123%4=3, 查询orders_3
SELECT
    id,
    total_amount,
    status,
    created_at
FROM orders_3
WHERE user_id = 123
ORDER BY created_at DESC
LIMIT 20;

-- 应用层代码示例（Python）
"""
def get_user_orders(user_id, limit=20):
    shard_index = user_id % 4
    table_name = f"orders_{shard_index}"

    sql = f'''
        SELECT id, total_amount, status, created_at
        FROM {table_name}
        WHERE user_id = %s
        ORDER BY created_at DESC
        LIMIT %s
    '''

    return db.query(sql, (user_id, limit))
"""
```

**需求2：查询某个订单详情（只知道order_id）**

```sql
-- 问题：不知道在哪个分表，需要查询所有分表

-- 方案1：遍历所有分表（性能差）
SELECT * FROM orders_0 WHERE id = 10001
UNION ALL
SELECT * FROM orders_1 WHERE id = 10001
UNION ALL
SELECT * FROM orders_2 WHERE id = 10001
UNION ALL
SELECT * FROM orders_3 WHERE id = 10001;

-- 优化1：添加LIMIT 1（找到后停止）
SELECT * FROM (
    SELECT * FROM orders_0 WHERE id = 10001
    UNION ALL
    SELECT * FROM orders_1 WHERE id = 10001
    UNION ALL
    SELECT * FROM orders_2 WHERE id = 10001
    UNION ALL
    SELECT * FROM orders_3 WHERE id = 10001
) t LIMIT 1;

-- 方案2：使用路由表（推荐，见下题）
```

### 8. 路由表设计

**创建路由表**：

```sql
CREATE TABLE order_route (
    order_id BIGINT PRIMARY KEY COMMENT '订单ID',
    user_id BIGINT NOT NULL COMMENT '用户ID',
    shard_index TINYINT NOT NULL COMMENT '分片索引',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',

    INDEX idx_user_id (user_id),
    INDEX idx_shard_index (shard_index),
    INDEX idx_created_at (created_at)
) ENGINE=InnoDB COMMENT='订单路由表';

-- 插入路由信息（从现有orders表）
INSERT INTO order_route (order_id, user_id, shard_index, created_at)
SELECT
    id AS order_id,
    user_id,
    (user_id % 4) AS shard_index,
    created_at
FROM orders;

-- 或者从分表插入
INSERT INTO order_route (order_id, user_id, shard_index)
SELECT id, user_id, 0 FROM orders_0
UNION ALL
SELECT id, user_id, 1 FROM orders_1
UNION ALL
SELECT id, user_id, 2 FROM orders_2
UNION ALL
SELECT id, user_id, 3 FROM orders_3;

-- 验证
SELECT COUNT(*) FROM order_route;
SELECT * FROM order_route LIMIT 10;
```

**使用路由表查询**：

```sql
-- 查询订单时先查路由表
SELECT shard_index
FROM order_route
WHERE order_id = 10001;
-- 假设返回：shard_index = 2

-- 根据shard_index定位到具体分表
SELECT *
FROM orders_2
WHERE id = 10001;

-- 应用层代码示例（Python）
"""
def get_order_by_id(order_id):
    # 1. 查路由表
    route = db.query_one(
        'SELECT shard_index FROM order_route WHERE order_id = %s',
        (order_id,)
    )

    if not route:
        return None

    # 2. 查对应分表
    shard_index = route['shard_index']
    table_name = f'orders_{shard_index}'

    sql = f'SELECT * FROM {table_name} WHERE id = %s'
    return db.query_one(sql, (order_id,))
"""

-- 一步查询（JOIN优化）
SELECT o.*
FROM order_route r
INNER JOIN orders_0 o ON r.order_id = o.id
WHERE r.order_id = 10001 AND r.shard_index = 0

UNION ALL

SELECT o.*
FROM order_route r
INNER JOIN orders_1 o ON r.order_id = o.id
WHERE r.order_id = 10001 AND r.shard_index = 1

UNION ALL

SELECT o.*
FROM order_route r
INNER JOIN orders_2 o ON r.order_id = o.id
WHERE r.order_id = 10001 AND r.shard_index = 2

UNION ALL

SELECT o.*
FROM order_route r
INNER JOIN orders_3 o ON r.order_id = o.id
WHERE r.order_id = 10001 AND r.shard_index = 3;
```

**路由表优化**：

```sql
-- 优化1：路由表也分表（如果路由表也很大）
CREATE TABLE order_route_0 LIKE order_route;
CREATE TABLE order_route_1 LIKE order_route;
CREATE TABLE order_route_2 LIKE order_route;
CREATE TABLE order_route_3 LIKE order_route;

-- 按order_id分片
-- order_id % 4 = 0 -> order_route_0

-- 优化2：使用Redis缓存路由信息
"""
import redis

r = redis.Redis()

def get_order_shard_index(order_id):
    # 先从Redis获取
    cache_key = f'order_route:{order_id}'
    shard_index = r.get(cache_key)

    if shard_index is None:
        # Redis没有，查数据库
        shard_index = db.query_one(
            'SELECT shard_index FROM order_route WHERE order_id = %s',
            (order_id,)
        )['shard_index']

        # 写入Redis缓存，过期时间1小时
        r.setex(cache_key, 3600, shard_index)

    return int(shard_index)
"""
```

## 四、分库分表的问题与解决方案

### 9. 全局唯一ID生成

**方案对比**：

| 方案 | 优点 | 缺点 | 适用场景 |
|------|------|------|----------|
| 雪花算法 | 性能高，ID有序 | 时钟回拨问题 | 高并发，需要ID有序 |
| 数据库号段 | 实现简单，可控 | 数据库压力 | 中等并发 |
| UUID | 全局唯一，无依赖 | 无序，存储大 | 不要求ID有序 |

**方案1：雪花算法（Snowflake）- 推荐**

```python
import time
import threading

class SnowflakeIDGenerator:
    """
    雪花算法ID生成器
    64位ID结构：
    - 1位：符号位（固定0）
    - 41位：时间戳（毫秒级，可用69年）
    - 10位：机器ID（支持1024个节点）
    - 12位：序列号（每毫秒可生成4096个ID）
    """

    def __init__(self, machine_id, datacenter_id=0):
        # 机器ID（0-31）
        self.machine_id = machine_id & 0x1F  # 5位
        # 数据中心ID（0-31）
        self.datacenter_id = datacenter_id & 0x1F  # 5位

        # 序列号
        self.sequence = 0
        # 上次生成ID的时间戳
        self.last_timestamp = -1

        # 起始时间戳（2024-01-01 00:00:00）
        self.epoch = 1704067200000

        # 锁
        self.lock = threading.Lock()

    def _current_millis(self):
        return int(time.time() * 1000)

    def _wait_next_millis(self, last_timestamp):
        timestamp = self._current_millis()
        while timestamp <= last_timestamp:
            timestamp = self._current_millis()
        return timestamp

    def generate_id(self):
        with self.lock:
            timestamp = self._current_millis()

            # 时钟回拨检测
            if timestamp < self.last_timestamp:
                raise Exception(f"时钟回拨！拒绝生成ID {self.last_timestamp - timestamp}ms")

            if timestamp == self.last_timestamp:
                # 同一毫秒内，序列号自增
                self.sequence = (self.sequence + 1) & 0xFFF  # 12位
                if self.sequence == 0:
                    # 序列号溢出，等待下一毫秒
                    timestamp = self._wait_next_millis(self.last_timestamp)
            else:
                # 新的毫秒，序列号重置为0
                self.sequence = 0

            self.last_timestamp = timestamp

            # 组装ID
            id = ((timestamp - self.epoch) << 22) | \
                 (self.datacenter_id << 17) | \
                 (self.machine_id << 12) | \
                 self.sequence

            return id

# 使用示例
id_generator = SnowflakeIDGenerator(machine_id=1, datacenter_id=1)

# 生成10个ID
for i in range(10):
    order_id = id_generator.generate_id()
    print(f"订单ID: {order_id}")

# 输出示例：
# 订单ID: 1234567890123456789
# 订单ID: 1234567890123456790
# ...
```

**优点**：
- 高性能（本地生成，无网络开销）
- ID递增（有利于数据库索引）
- 包含时间信息（可解析出生成时间）

**缺点**：
- 依赖机器时钟（时钟回拨会导致ID冲突）
- 需要分配机器ID（分布式环境需协调）

**方案2：数据库号段模式**

```sql
-- 创建ID生成表
CREATE TABLE id_generator (
    biz_type VARCHAR(50) PRIMARY KEY COMMENT '业务类型',
    max_id BIGINT NOT NULL COMMENT '当前最大ID',
    step INT NOT NULL DEFAULT 1000 COMMENT '步长',
    update_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    INDEX idx_update_time (update_time)
) ENGINE=InnoDB COMMENT='分布式ID生成器';

-- 插入初始数据
INSERT INTO id_generator (biz_type, max_id, step)
VALUES
    ('order', 100000, 1000),
    ('user', 10000, 100),
    ('product', 50000, 500);

-- 获取ID号段（应用层原子操作）
UPDATE id_generator
SET max_id = max_id + step
WHERE biz_type = 'order';

SELECT max_id, step
FROM id_generator
WHERE biz_type = 'order';

-- 假设返回：max_id=101000, step=1000
-- 应用层可以使用100001~101000这1000个ID
```

**应用层实现**：

```python
class SegmentIDGenerator:
    """数据库号段ID生成器"""

    def __init__(self, db, biz_type):
        self.db = db
        self.biz_type = biz_type
        self.current_id = 0
        self.max_id = 0
        self.step = 0
        self.lock = threading.Lock()

    def _fetch_segment(self):
        """从数据库获取新号段"""
        # 更新max_id并返回
        self.db.execute(
            'UPDATE id_generator SET max_id = max_id + step WHERE biz_type = %s',
            (self.biz_type,)
        )

        result = self.db.query_one(
            'SELECT max_id, step FROM id_generator WHERE biz_type = %s',
            (self.biz_type,)
        )

        self.max_id = result['max_id']
        self.step = result['step']
        self.current_id = self.max_id - self.step + 1

    def generate_id(self):
        """生成ID"""
        with self.lock:
            if self.current_id >= self.max_id:
                # 当前号段用完，获取新号段
                self._fetch_segment()

            self.current_id += 1
            return self.current_id

# 使用
id_gen = SegmentIDGenerator(db, 'order')
order_id = id_gen.generate_id()
```

**优点**：
- 实现简单
- 可控性强（可以设置起始ID、步长）
- ID递增

**缺点**：
- 依赖数据库（单点故障风险）
- 数据库压力（高并发时需要优化）
- 号段用完需要访问数据库

**方案3：UUID**

```sql
-- MySQL生成UUID
SELECT UUID() AS order_id;
-- 输出：550e8400-e29b-41d4-a716-446655440000

-- 有序UUID（MySQL 8.0+）
SELECT UUID_TO_BIN(UUID(), 1) AS order_id;

-- 去掉横线的UUID
SELECT REPLACE(UUID(), '-', '') AS order_id;
-- 输出：550e8400e29b41d4a716446655440000
```

**应用层生成**：

```python
import uuid

# 随机UUID（UUID4）
order_id = str(uuid.uuid4())
print(order_id)  # 550e8400-e29b-41d4-a716-446655440000

# 去掉横线
order_id = uuid.uuid4().hex
print(order_id)  # 550e8400e29b41d4a716446655440000

# 有序UUID（UUID1，基于时间和MAC地址）
order_id = str(uuid.uuid1())
```

**优点**：
- 生成简单，无依赖
- 全局唯一（概率极低的冲突）

**缺点**：
- 无序（不利于数据库索引）
- 存储空间大（36字符或128位）
- 无业务含义

**推荐方案：雪花算法**

理由：
1. 订单ID需要递增（用户体验好，ID从小到大）
2. 高性能（本地生成，QPS可达百万级）
3. 包含时间信息（便于按ID范围查询某时间段订单）
4. 64位长整型（比UUID节省空间）

### 10. 分布式事务处理

**场景分析**：

```
创建订单流程：
1. 扣减库存（product_db.product_skus）
2. 创建订单（order_db.orders_2）
3. 创建订单明细（order_db.order_items_2）
4. 创建支付记录（order_db.payments_2）

问题：跨数据库操作，无法使用本地事务保证原子性
```

**解决方案对比**：

| 方案 | 一致性 | 性能 | 复杂度 | 适用场景 |
|------|--------|------|--------|----------|
| XA事务 | 强一致 | 低 | 中 | 金融、支付 |
| TCC | 强一致 | 中 | 高 | 对一致性要求高的场景 |
| 本地消息表 | 最终一致 | 高 | 中 | 大部分业务场景 |
| SAGA | 最终一致 | 高 | 高 | 长事务、复杂流程 |

**方案1：XA事务（两阶段提交）**

```python
# 伪代码
xa = XATransaction()

try:
    # 阶段1：准备（Prepare）
    xa.start('product_db')
    product_db.execute('UPDATE product_skus SET stock = stock - 1 WHERE sku_id = ?', (sku_id,))
    xa.end('product_db')
    xa.prepare('product_db')

    xa.start('order_db')
    order_db.execute('INSERT INTO orders_2 (...) VALUES (...)')
    order_db.execute('INSERT INTO order_items_2 (...) VALUES (...)')
    xa.end('order_db')
    xa.prepare('order_db')

    # 阶段2：提交（Commit）
    xa.commit('product_db')
    xa.commit('order_db')

except Exception as e:
    # 回滚
    xa.rollback('product_db')
    xa.rollback('order_db')
    raise
```

**优点**：强一致性
**缺点**：
- 性能差（两阶段提交，锁定时间长）
- 阻塞（Prepare后资源被锁定）
- 单点故障（协调者宕机导致阻塞）

**方案2：TCC（Try-Confirm-Cancel）**

```python
# TCC三阶段

# Try阶段：预留资源
def try_create_order(order_data, sku_id, quantity):
    # 1. 冻结库存（不直接扣减）
    product_db.execute('''
        UPDATE product_skus
        SET stock = stock - ?, frozen_stock = frozen_stock + ?
        WHERE sku_id = ? AND stock >= ?
    ''', (quantity, quantity, sku_id, quantity))

    # 2. 创建订单（状态为'预创建'）
    order_db.execute('''
        INSERT INTO orders_2 (user_id, status, ...)
        VALUES (?, 'pre_created', ...)
    ''', (...))

    return transaction_id

# Confirm阶段：确认提交
def confirm_create_order(transaction_id):
    # 1. 确认扣库存（从冻结转为实际扣减）
    product_db.execute('''
        UPDATE product_skus
        SET frozen_stock = frozen_stock - ?
        WHERE sku_id = ?
    ''', (quantity, sku_id))

    # 2. 订单状态改为'已创建'
    order_db.execute('''
        UPDATE orders_2
        SET status = 'created'
        WHERE transaction_id = ?
    ''', (transaction_id,))

# Cancel阶段：取消回滚
def cancel_create_order(transaction_id):
    # 1. 解冻库存
    product_db.execute('''
        UPDATE product_skus
        SET stock = stock + ?, frozen_stock = frozen_stock - ?
        WHERE sku_id = ?
    ''', (quantity, quantity, sku_id))

    # 2. 删除订单或标记为取消
    order_db.execute('''
        UPDATE orders_2
        SET status = 'cancelled'
        WHERE transaction_id = ?
    ''', (transaction_id,))

# 主流程
transaction_id = try_create_order(order_data, sku_id, quantity)
try:
    # 执行其他业务逻辑
    ...
    # 成功则确认
    confirm_create_order(transaction_id)
except Exception as e:
    # 失败则取消
    cancel_create_order(transaction_id)
```

**优点**：
- 强一致性
- 不阻塞（Try阶段仅预留，不锁定）

**缺点**：
- 实现复杂（需要实现Try/Confirm/Cancel三套逻辑）
- 业务侵入性强

**方案3：本地消息表（推荐）**

```sql
-- 创建本地消息表
CREATE TABLE local_message (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    transaction_id VARCHAR(50) UNIQUE NOT NULL COMMENT '事务ID',
    biz_type VARCHAR(50) NOT NULL COMMENT '业务类型',
    content JSON NOT NULL COMMENT '消息内容',
    status ENUM('pending','sent','consumed','failed') DEFAULT 'pending',
    retry_count INT DEFAULT 0 COMMENT '重试次数',
    max_retry INT DEFAULT 3,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

    INDEX idx_status_created (status, created_at)
) ENGINE=InnoDB;
```

**流程**：

```python
# 步骤1：创建订单 + 写本地消息表（在同一本地事务中）
@transaction  # 本地事务
def create_order(order_data, sku_id, quantity):
    # 1. 创建订单
    order_id = order_db.execute('''
        INSERT INTO orders_2 (user_id, total_amount, status, ...)
        VALUES (?, ?, 'pending', ...)
    ''', (...))

    # 2. 写本地消息表（与订单在同一数据库）
    order_db.execute('''
        INSERT INTO local_message (transaction_id, biz_type, content, status)
        VALUES (?, 'reduce_stock', ?, 'pending')
    ''', (transaction_id, json.dumps({
        'sku_id': sku_id,
        'quantity': quantity,
        'order_id': order_id
    })))

    return order_id

# 步骤2：定时任务扫描消息表并发送
def send_pending_messages():
    messages = order_db.query('''
        SELECT * FROM local_message
        WHERE status = 'pending' AND retry_count < max_retry
        ORDER BY created_at
        LIMIT 100
    ''')

    for msg in messages:
        try:
            # 发送到消息队列（RabbitMQ/Kafka）
            mq.send('reduce_stock_queue', msg['content'])

            # 更新消息状态
            order_db.execute('''
                UPDATE local_message
                SET status = 'sent'
                WHERE id = ?
            ''', (msg['id'],))
        except Exception as e:
            # 重试
            order_db.execute('''
                UPDATE local_message
                SET retry_count = retry_count + 1
                WHERE id = ?
            ''', (msg['id'],))

# 步骤3：消费者处理消息
def consume_reduce_stock_message(message):
    content = json.loads(message)
    sku_id = content['sku_id']
    quantity = content['quantity']

    # 扣减库存（幂等性：使用订单ID作为去重键）
    product_db.execute('''
        UPDATE product_skus
        SET stock = stock - ?
        WHERE sku_id = ? AND stock >= ?
    ''', (quantity, sku_id, quantity))

    # 记录已处理（防止重复消费）
    product_db.execute('''
        INSERT IGNORE INTO processed_messages (transaction_id, processed_at)
        VALUES (?, NOW())
    ''', (message['transaction_id'],))

# 步骤4：更新订单状态（通过MQ通知）
def on_stock_reduced(order_id):
    order_db.execute('''
        UPDATE orders_2
        SET status = 'created'
        WHERE id = ?
    ''', (order_id,))
```

**优点**：
- 实现相对简单
- 性能好（异步处理）
- 业务侵入小

**缺点**：
- 最终一致性（有延迟）
- 需要消息队列
- 需要实现幂等性

**推荐方案：本地消息表**

适用于大部分电商订单场景：
- 订单创建和库存扣减可以短时间不一致
- 性能要求高
- 可以接受秒级延迟

### 11. 跨分片Join查询

**原查询（单表）**：

```sql
SELECT o.id, o.total_amount, o.status, oi.product_id, oi.quantity, oi.price
FROM orders o
INNER JOIN order_items oi ON o.id = oi.order_id
WHERE o.user_id = 123
ORDER BY o.created_at DESC
LIMIT 20;
```

**分表后的问题**：
- orders按user_id分片 -> orders_3 (123%4=3)
- order_items按什么分片？
  - 方案A：按order_id分片 -> 跨分片Join
  - 方案B：按user_id分片 -> 同分片Join

**解决方案1：应用层Join（推荐）**

```python
def get_user_orders_with_items(user_id, limit=20):
    # 步骤1：查询订单（单分片）
    shard_index = user_id % 4
    orders = db.query(f'''
        SELECT id, total_amount, status, created_at
        FROM orders_{shard_index}
        WHERE user_id = %s
        ORDER BY created_at DESC
        LIMIT %s
    ''', (user_id, limit))

    if not orders:
        return []

    # 步骤2：提取订单ID列表
    order_ids = [o['id'] for o in orders]

    # 步骤3：查询订单明细（可能跨多个分片）
    items_dict = {}
    for i in range(4):  # 遍历4个分片
        items = db.query(f'''
            SELECT order_id, product_id, quantity, price
            FROM order_items_{i}
            WHERE order_id IN ({','.join(['%s'] * len(order_ids))})
        ''', order_ids)

        for item in items:
            order_id = item['order_id']
            if order_id not in items_dict:
                items_dict[order_id] = []
            items_dict[order_id].append(item)

    # 步骤4：组装结果
    for order in orders:
        order['items'] = items_dict.get(order['id'], [])

    return orders

# 结果：
# [
#   {
#     'id': 10001,
#     'total_amount': 500.00,
#     'status': 'paid',
#     'created_at': '2024-01-15',
#     'items': [
#       {'product_id': 101, 'quantity': 2, 'price': 100.00},
#       {'product_id': 102, 'quantity': 3, 'price': 100.00}
#     ]
#   },
#   ...
# ]
```

**解决方案2：数据冗余（空间换时间）**

```sql
-- 在order_items中冗余user_id
CREATE TABLE order_items_0 (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    order_id BIGINT NOT NULL,
    user_id BIGINT NOT NULL,  -- 冗余字段
    product_id BIGINT NOT NULL,
    quantity INT NOT NULL,
    price DECIMAL(10,2) NOT NULL,

    INDEX idx_user_id (user_id),
    INDEX idx_order_id (order_id)
) ENGINE=InnoDB;

-- order_items也按user_id分片
-- 这样orders和order_items在同一分片
INSERT INTO order_items_2
SELECT *, (SELECT user_id FROM orders WHERE id = order_items.order_id)
FROM order_items
WHERE (SELECT user_id FROM orders WHERE id = order_items.order_id) % 4 = 2;

-- 查询变为单分片Join
SELECT o.id, o.total_amount, oi.product_id, oi.quantity
FROM orders_3 o
INNER JOIN order_items_3 oi ON o.id = oi.order_id
WHERE o.user_id = 123
ORDER BY o.created_at DESC
LIMIT 20;
```

**优点**：
- 查询快（单分片Join）
- SQL简单

**缺点**：
- 数据冗余（浪费存储空间）
- 一致性维护（user_id变更时需要同步更新）

**解决方案3：宽表设计**

```sql
-- 合并orders和order_items为宽表
CREATE TABLE order_detail_0 (
    order_id BIGINT NOT NULL,
    user_id BIGINT NOT NULL,
    total_amount DECIMAL(10,2),
    status VARCHAR(20),
    order_created_at TIMESTAMP,

    item_id BIGINT,
    product_id BIGINT,
    quantity INT,
    price DECIMAL(10,2),

    PRIMARY KEY (order_id, item_id),
    INDEX idx_user_id (user_id)
) ENGINE=InnoDB;

-- 一条订单多个商品 -> 多行记录
-- 查询
SELECT *
FROM order_detail_3
WHERE user_id = 123
ORDER BY order_created_at DESC
LIMIT 20;
```

**优点**：
- 查询最快（无Join）
- 单分片查询

**缺点**：
- 数据冗余最严重
- 更新复杂（如订单状态变更，需更新多行）

**推荐：应用层Join**

理由：
- 灵活性高，易于维护
- 不引入数据冗余
- 性能可接受（通过缓存优化）

### 12. 分页查询优化

**场景分析**：

```sql
-- 原查询（单表）
SELECT * FROM orders
WHERE user_id = 123
ORDER BY created_at DESC
LIMIT 20 OFFSET 0;  -- 第1页

-- 分表后（已知user_id，单分片查询）
SELECT * FROM orders_3
WHERE user_id = 123
ORDER BY created_at DESC
LIMIT 20 OFFSET 0;

-- 问题：跨分片分页（不知道user_id）
-- 场景：管理后台查看所有订单
SELECT * FROM orders
WHERE status = 'paid'
ORDER BY created_at DESC
LIMIT 20 OFFSET 100;
```

**问题：跨分片分页**

```sql
-- 错误方式：分别查询再合并
SELECT * FROM orders_0 WHERE status = 'paid' ORDER BY created_at DESC LIMIT 20 OFFSET 100
UNION ALL
SELECT * FROM orders_1 WHERE status = 'paid' ORDER BY created_at DESC LIMIT 20 OFFSET 100
UNION ALL
SELECT * FROM orders_2 WHERE status = 'paid' ORDER BY created_at DESC LIMIT 20 OFFSET 100
UNION ALL
SELECT * FROM orders_3 WHERE status = 'paid' ORDER BY created_at DESC LIMIT 20 OFFSET 100
ORDER BY created_at DESC
LIMIT 20;

-- 问题：结果不正确
-- 假设4个分片各返回20条（共80条）
-- 真正的第101-120名可能不在这80条中
```

**正确方式：全局归并**

```python
def get_paid_orders_paginated(page, page_size=20):
    offset = (page - 1) * page_size

    # 步骤1：从每个分片取前(offset + page_size)条
    # 为什么？因为全局第101-120名可能分布在任意分片
    fetch_limit = offset + page_size

    all_orders = []

    for i in range(4):
        orders = db.query(f'''
            SELECT * FROM orders_{i}
            WHERE status = 'paid'
            ORDER BY created_at DESC
            LIMIT {fetch_limit}
        ''')
        all_orders.extend(orders)

    # 步骤2：应用层全局排序
    all_orders.sort(key=lambda x: x['created_at'], reverse=True)

    # 步骤3：取第offset到offset+page_size
    result = all_orders[offset : offset + page_size]

    return result

# 示例：查询第6页（第101-120条）
orders = get_paid_orders_paginated(page=6, page_size=20)
```

**性能分析**：

```
查询第1页（0-20）：
- 每个分片取20条，共80条
- 应用层排序80条，取前20条
- 性能：可接受

查询第100页（1980-2000）：
- 每个分片取2000条，共8000条
- 应用层排序8000条，取1980-2000
- 性能：差

问题：深度分页性能差
```

**优化方案1：禁止深度分页**

```python
MAX_PAGE = 100  # 最多查询100页

def get_paid_orders_paginated(page, page_size=20):
    if page > MAX_PAGE:
        raise Exception(f"分页深度不能超过{MAX_PAGE}页")

    # ... 同上
```

**优化方案2：游标分页（推荐）**

```python
def get_paid_orders_cursor_paginated(last_created_at=None, page_size=20):
    """
    基于游标的分页
    last_created_at: 上一页最后一条记录的created_at
    """
    all_orders = []

    for i in range(4):
        if last_created_at:
            # 查询created_at小于游标的记录
            orders = db.query(f'''
                SELECT * FROM orders_{i}
                WHERE status = 'paid'
                  AND created_at < %s
                ORDER BY created_at DESC
                LIMIT {page_size}
            ''', (last_created_at,))
        else:
            # 第一页
            orders = db.query(f'''
                SELECT * FROM orders_{i}
                WHERE status = 'paid'
                ORDER BY created_at DESC
                LIMIT {page_size}
            ''')

        all_orders.extend(orders)

    # 全局排序
    all_orders.sort(key=lambda x: x['created_at'], reverse=True)

    # 返回前page_size条
    return all_orders[:page_size]

# 使用
# 第1页
page1 = get_paid_orders_cursor_paginated(last_created_at=None, page_size=20)

# 第2页（使用第1页最后一条的created_at作为游标）
last_created_at = page1[-1]['created_at']
page2 = get_paid_orders_cursor_paginated(last_created_at=last_created_at, page_size=20)
```

**游标分页优点**：
- 性能稳定（无论查询第几页，都只取page_size条）
- 适合实时数据（如社交feeds）

**缺点**：
- 不能跳页（只能上一页/下一页）
- 需要唯一有序字段作为游标

**优化方案3：搜索引擎（Elasticsearch）**

```python
# 将订单数据同步到ES
# 在ES中做分页查询

from elasticsearch import Elasticsearch

es = Elasticsearch(['localhost:9200'])

def search_paid_orders(page, page_size=20):
    from_offset = (page - 1) * page_size

    result = es.search(
        index='orders',
        body={
            'query': {
                'term': {'status': 'paid'}
            },
            'sort': [
                {'created_at': {'order': 'desc'}}
            ],
            'from': from_offset,
            'size': page_size
        }
    )

    return [hit['_source'] for hit in result['hits']['hits']]

# ES内部已经优化了分布式分页
```

### 13. 数据聚合查询

**场景：统计所有订单总金额**

```sql
-- 原查询（单表）
SELECT SUM(total_amount) AS total_sales FROM orders;

-- 分表后（错误方式）
SELECT SUM(total_amount) FROM orders_0
UNION ALL
SELECT SUM(total_amount) FROM orders_1;
-- 结果：多行，不是总和

-- 正确方式1：子查询
SELECT SUM(total_amount) AS total_sales FROM (
    SELECT total_amount FROM orders_0
    UNION ALL
    SELECT total_amount FROM orders_1
    UNION ALL
    SELECT total_amount FROM orders_2
    UNION ALL
    SELECT total_amount FROM orders_3
) AS all_orders;

-- 正确方式2：分别聚合再求和（推荐，性能更好）
SELECT
    (SELECT SUM(total_amount) FROM orders_0) +
    (SELECT SUM(total_amount) FROM orders_1) +
    (SELECT SUM(total_amount) FROM orders_2) +
    (SELECT SUM(total_amount) FROM orders_3) AS total_sales;
```

**应用层聚合（推荐）**：

```python
def get_total_sales():
    total = 0

    for i in range(4):
        shard_total = db.query_one(f'''
            SELECT IFNULL(SUM(total_amount), 0) AS shard_total
            FROM orders_{i}
        ''')['shard_total']

        total += shard_total

    return total

# 并行查询优化
import concurrent.futures

def get_total_sales_parallel():
    def query_shard(i):
        return db.query_one(f'''
            SELECT IFNULL(SUM(total_amount), 0) AS shard_total
            FROM orders_{i}
        ''')['shard_total']

    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
        futures = [executor.submit(query_shard, i) for i in range(4)]
        results = [f.result() for f in concurrent.futures.as_completed(futures)]

    return sum(results)
```

**复杂聚合示例**：

```sql
-- 统计每日订单数和销售额
-- 应用层实现
```

```python
def get_daily_sales_stats():
    all_stats = []

    # 从每个分片查询
    for i in range(4):
        stats = db.query(f'''
            SELECT
                DATE(created_at) AS order_date,
                COUNT(*) AS order_count,
                SUM(total_amount) AS daily_sales
            FROM orders_{i}
            GROUP BY DATE(created_at)
            ORDER BY order_date DESC
            LIMIT 30
        ''')
        all_stats.extend(stats)

    # 应用层再次聚合（按日期分组）
    from collections import defaultdict

    merged_stats = defaultdict(lambda: {'order_count': 0, 'daily_sales': 0})

    for stat in all_stats:
        date = stat['order_date']
        merged_stats[date]['order_count'] += stat['order_count']
        merged_stats[date]['daily_sales'] += stat['daily_sales']

    # 转换为列表并排序
    result = [
        {
            'order_date': date,
            'order_count': data['order_count'],
            'daily_sales': data['daily_sales']
        }
        for date, data in merged_stats.items()
    ]

    result.sort(key=lambda x: x['order_date'], reverse=True)

    return result[:30]  # 返回最近30天
```

## 综合总结

分库分表是解决数据量大、并发高的有效手段，但也带来了复杂性：

**核心要点**：
1. **垂直拆分优先**：先按业务拆分数据库，再考虑水平拆分
2. **分片键选择**：关乎查询效率，选择最常用的查询维度
3. **全局ID**：雪花算法是推荐方案
4. **路由表**：解决非分片键查询问题
5. **分布式事务**：本地消息表适合大部分场景
6. **跨分片查询**：尽量避免，通过应用层处理
7. **监控运维**：密切关注数据倾斜、分片性能

**最佳实践**：
- 评估是否真的需要分库分表（优化先行）
- 预留扩容空间（考虑未来3-5年数据增长）
- 完善的监控和告警
- 制定数据迁移和扩容方案
- 使用成熟的中间件（ShardingSphere、Mycat）
